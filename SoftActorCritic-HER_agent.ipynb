{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parking_sac_her.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoikorda/self-driving-cars/blob/main/SoftActorCritic-HER_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc6C9OlN9RaN"
      },
      "source": [
        "# Install environment and agent\n",
        "!pip install highway-env\n",
        "!pip install stable-baselines3\n",
        "!pip install sb3-contrib\n",
        "\n",
        "# Environment\n",
        "import gym\n",
        "import highway_env\n",
        "\n",
        "# Agent\n",
        "from stable_baselines3 import HerReplayBuffer, SAC\n",
        "from sb3_contrib import TQC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "WiKifR5rspKF"
      },
      "source": [
        "env = gym.make(\"parking-v0\")\n",
        "her_kwargs = dict(n_sampled_goal=4, goal_selection_strategy='future', online_sampling=True, max_episode_length=100)\n",
        "# You can replace TQC with SAC agent\n",
        "model = SAC('MultiInputPolicy', env, replay_buffer_class=HerReplayBuffer,\n",
        "            replay_buffer_kwargs=her_kwargs, verbose=1, buffer_size=int(1e6),\n",
        "            learning_rate=1e-3,\n",
        "            gamma=0.95, batch_size=1024, tau=0.05,\n",
        "            policy_kwargs=dict(net_arch=[512, 512, 512]))\n",
        "model.learn(int(5e4))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so7yH4ucyB-3"
      },
      "source": [
        "!pip install gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "from gym.wrappers import Monitor\n",
        "from pathlib import Path\n",
        "import base64\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "    html = []\n",
        "    for mp4 in Path(\"video\").glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay \n",
        "                      loop controls style=\"height: 400px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3sxhf1Q6NlL"
      },
      "source": [
        "obs = env.reset()\n",
        "\n",
        "# Evaluate the agent\n",
        "rewards = []\n",
        "episode_reward = 0\n",
        "for _ in range(1000):\n",
        "  action, _ = model.predict(obs)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  episode_reward += reward\n",
        "  if done or info.get('is_success', False):\n",
        "    print(\"Reward:\", episode_reward, \"Success?\", info.get('is_success', False))\n",
        "    rewards.append(episode_reward)\n",
        "    episode_reward = 0.0\n",
        "    obs = env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOcOP7Of18T2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "env = gym.make(\"parking-v0\")\n",
        "env = Monitor(env, './video', force=True, video_callable=lambda episode: True)\n",
        "rewards = []\n",
        "for episode in trange(3, desc=\"Test episodes\"):\n",
        "    obs, done = env.reset(), False\n",
        "    env.unwrapped.automatic_rendering_callback = env.video_recorder.capture_frame\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        rewards.append(reward)\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq63cXwWQhf3"
      },
      "source": [
        "print(rewards)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(1, len(rewards)+1), rewards)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpqk32a8X2ZJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}